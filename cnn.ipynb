{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando uma CNN para reconhecimento de imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_O objetivo desse notebook é implementar uma rede neural convolucional que tem como função reconhecer se a imagem inputada é de um cachorro ou de um gato._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grupo: Daniel Augusto, Douglas Abdo, Matheus Fialho e Rennan Haro.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramentas utilizadas: [TensorFlow](https://www.tensorflow.org), [Keras](https://keras.io). <br>\n",
    "**Para rodar a rede neural em sua máquina, instale o [Python (3.6+)](https://python.org/download) ou [Anaconda](https://www.anaconda.com/products/individual) e execute o comando `$ pip install -r requirements.txt`** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps para implementaçao da CNN\n",
    "- Importar as bibliotecas necessárias\n",
    "- Coletar o dataset\n",
    "- Separar o dataset (split)\n",
    "- Setar as varáveis para a construção da CNN\n",
    "- Estruturar a CNN\n",
    "- Data augmentation\n",
    "- Treinar a nossa rede neural\n",
    "- Testar nosso algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante: execute o comando `$ pip install -r requirements.txt` antes de prosseguir com esse step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os modulos do Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os modulos adicionais\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 e 3 - Coletando e splitando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Encontre mais informações sobre o dataset e downloads adicionais [neste link](https://www.kaggle.com/c/dogs-vs-cats/data)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os datasets estão na pasta `data`. Consistem em basicamente 4 datasets (2 para treinar e 2 para testar), totalizando 2.800 imagens. 1.400 imagens de gatos e 1.400 imagens de cachorros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O split do dataset já foi feito. <br>\n",
    "Temos em nosso dataset de treino 1.000 imagens de cachorros e 1.000 imagens de gatos. <br>\n",
    "O nosso datset de teste, por sua vez, possui 400 imagens de cada.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagem](assets/kaggle_dataset.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Setando variáveis (hiperparâmetros) para construção da nossa CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150 # Dimensão das imagens\n",
    "\n",
    "train_data_dir = 'data/train' # Diretório com dados para treino\n",
    "validation_data_dir = 'data/validation' # Diretório com dados para teste\n",
    "\n",
    "nb_train_samples = 2000 # Quantidade de samples para treino\n",
    "nb_validation_samples = 800 # Quantidade de samples para teste\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# Setando o shape das imagens inputadas\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Construindo a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaração do modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Adicionando os layers em nosso modelo\n",
    "# Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Definindo modelo\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Treinando nossa CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Testando nossa CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('random.png', target_size = (150, 150))\n",
    "#test_image = image.load_img('data/validation/dogs/dog.10500.jpg', target_size = (150, 150))\n",
    "#test_image = image.load_img('data/validation/cats/cat.1000.jpg', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = test_image/.255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "train_generator.class_indices\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
